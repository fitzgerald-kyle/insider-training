{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55050497-5c36-4f51-a496-72be969269a0",
   "metadata": {},
   "source": [
    "## Training with a Neural Network\n",
    "This notebook contains the training of a Keras Sequential model on insider data, which attempts to predict the maximum 90-day percentage gain of a ticker whose insider(s) made a trade. We use a single dense hidden layer and a dropout layer, and we use the Keras Tuner to choose an optimal learning rate and number of hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85b09665",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport my_functions\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from operator import itemgetter\n",
    "\n",
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525a07b1-e849-4aaf-a3b8-7afa0cb2b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS_TO_LOOK_BACK = 6  # used for calculating volume volatility and recent-trade counts\n",
    "\n",
    "train_and_cv = my_model_prep.prepareForModel(pd.read_csv('data/training_and_cv_data.csv'))\n",
    "\n",
    "startDate = min(train_and_cv.FilingDate) + dt.timedelta(days=DAYS_TO_LOOK_BACK)\n",
    "endDate = max(train_and_cv.FilingDate)\n",
    "splitDate = startDate + dt.timedelta(days=int(0.9*(endDate-startDate).days))\n",
    "\n",
    "train_XY, train_X, train_Y = my_model_prep.returnXandY(\n",
    "    train_and_cv, dt.date.isoformat(startDate), dt.date.isoformat(splitDate), binStarts=[-10, 0, 20]\n",
    ")\n",
    "\n",
    "cv_XY, cv_X, cv_Y = my_model_prep.returnXandY(\n",
    "    train_and_cv, dt.date.isoformat(splitDate+dt.timedelta(days=1)), dt.date.isoformat(endDate)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f335100-3104-4d2a-91f2-dc4f270210e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (11082, 17)\n",
      "cv shape: (1618, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape: {train_X.shape}')\n",
    "print(f'cv shape: {cv_X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b828936-c6db-4a88-a517-f80936deae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Perform standard feature normalization.\n",
    "'''\n",
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X)\n",
    "cv_X_scaled = scaler.fit_transform(cv_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb894f1-e2e4-4c53-bb32-48fe30f1e5f7",
   "metadata": {},
   "source": [
    "Here is a StackExchange answer that provides a starting point for deciding on the number of hidden units to include: https://stats.stackexchange.com/a/136542\n",
    "\n",
    "### Below is a computation to obtain the absolute maximum number of hidden units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13153c21-12df-4657-ace4-ca672f1f67e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An upper bound for number of hidden units: 307\n"
     ]
    }
   ],
   "source": [
    "Ns = train_X_scaled.shape[0]  # training examples\n",
    "No = 1                           # output neurons\n",
    "Ni = train_X_scaled.shape[1]  # input neurons\n",
    "alpha = 2                        # scale factor\n",
    "\n",
    "Nh = Ns / (alpha*(Ni + No))      # maximum hidden neurons\n",
    "\n",
    "print(f'An upper bound for number of hidden units: {int(Nh)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2a62b-e0b8-4899-bcce-7d0465084faa",
   "metadata": {},
   "source": [
    "This seems like *quite* a lot; we certainly don't need this many hidden units! \n",
    "\n",
    "### However, we can remove some of the guesswork by using Keras Tuner. \n",
    "With this tool, we can search the parameter space and also determine an optimal number of hidden units.\n",
    "\n",
    "We have 16 inputs, so let's opt for one Dense and one Dropout hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2cadd234-2198-48ad-92ca-5d79a6ea522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNDERESTIMATE_BIAS = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31ebcc42-8066-4646-9330-0fac84929292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops, numpy_ops\n",
    "numpy_ops.np_config.enable_numpy_behavior()\n",
    "\n",
    "#def asymmetric_loss(wgt):\n",
    "'''This is our custom objective loss function that favors either underestimates (wgt > 1)\n",
    "or overestimates (0 < wgt < 1).'''\n",
    "def asymm_mse(y_true, y_pred):\n",
    "    diff = UNDERESTIMATE_BIAS*math_ops.squared_difference(y_pred, y_true)*(y_true < y_pred).astype(float) + \\\n",
    "            math_ops.squared_difference(y_pred, y_true)*(y_true >= y_pred).astype(float)\n",
    "\n",
    "    loss = tf.math.sqrt(tf.reduce_mean(diff, axis=-1))\n",
    "\n",
    "    return loss\n",
    "    #return asymm_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a21264-d7c1-4c04-85ae-0226c2e9bf22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "tf.random.set_seed(40)\n",
    "\n",
    "def model_builder(numFeatures):\n",
    "    def builder(tuner):\n",
    "        numUnits = tuner.Int('units', min_value=4, max_value=32, step=4)\n",
    "        learningRate = tuner.Choice('learningRate', values=[1e-2, 1e-3, 1e-4])\n",
    "        dropoutRate = tuner.Choice('dropoutRate', values=[0., 0.1, 0.2])\n",
    "        \n",
    "        model = Sequential(\n",
    "            [               \n",
    "                Input(shape=(numFeatures,)),\n",
    "                Dense(units=numUnits, activation='relu', name='dense_1'),\n",
    "                Dropout(dropoutRate),\n",
    "                Dense(units=numUnits/2, activation='relu', name='dense_2'),\n",
    "                Dropout(dropoutRate),\n",
    "                Dense(units=1, activation='linear', name='dense_out')\n",
    "            ], name = 'nn_model' \n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learningRate),\n",
    "            loss=asymm_mse,\n",
    "            metrics=asymm_mse\n",
    "        )\n",
    "\n",
    "        return model\n",
    "    return builder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82daf77f-9ee1-462d-a611-7e5602cc5b16",
   "metadata": {},
   "source": [
    "Hyperband is an algorithm that searches the hyperparameter space with respect to which we want to minimize the evaluation metric, i.e. the custom asymmetric loss. \n",
    "\n",
    "We use EarlyStopping to halt training early if there is no loss improvement in the 10 most recent epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ef163f2-77db-44c0-9e33-f67a3813e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 00m 02s]\n",
      "asymm_mse: 15.461211204528809\n",
      "\n",
      "Best asymm_mse So Far: 14.532682418823242\n",
      "Total elapsed time: 00h 01m 51s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    model_builder(train_X_scaled.shape[1]),\n",
    "    objective=kt.Objective('asymm_mse', 'min'),\n",
    "    max_epochs=100,\n",
    "    overwrite=True,\n",
    "    directory='tuner logs',\n",
    "    project_name=f'asymm_mse({int(UNDERESTIMATE_BIAS)})'\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    train_X_scaled, train_Y, \n",
    "    epochs=100,\n",
    "    validation_data=(cv_X_scaled, cv_Y),\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)]\n",
    ")\n",
    "\n",
    "best_hparams = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b8459e7-cb83-4c07-8dea-da9fddf38565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the best hyperparameter values: \n",
      " {'units': 16, 'learningRate': 0.01, 'dropoutRate': 0.0, 'tuner/epochs': 2, 'tuner/initial_epoch': 0, 'tuner/bracket': 4, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "print(f'These are the best hyperparameter values: \\n {best_hparams.values}')\n",
    "nn_model = tuner.hypermodel.build(best_hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb08d509-4793-406b-8523-dea17ada4412",
   "metadata": {},
   "source": [
    "We aren't surprised to see that loss is minimized for UNDERESTIMATE_BIAS=1, i.e. a symmetric mean squared error, because increasing the bias directly increases the loss accumulated from each overestimate. I initially thought about only allowing values greater than 1, but as will be seen below, we have another, more pressing problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72fb598e-5c57-4a60-9c73-7500f4861c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347/347 [==============================] - 0s 917us/step\n",
      "51/51 [==============================] - 0s 831us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-e69f1d4ae9b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcv_Y_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_X_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'\\ncv MSE: {asymm_mse(cv_Y, cv_Y_preds)}\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdfcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'cvPreds'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_Y_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcv_Y_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cvVals'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcv_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-e16b735ce0a2>\u001b[0m in \u001b[0;36masymm_mse\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m      6\u001b[0m or overestimates (0 < wgt < 1).'''\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masymm_mse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUNDERESTIMATE_BIAS\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__lt__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__lt__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__lt__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cmp_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__le__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5623\u001b[0m             \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5624\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5625\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5627\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_logical_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_construct_result\u001b[1;34m(self, result, name)\u001b[0m\n\u001b[0;32m   3015\u001b[0m         \u001b[1;31m# We do not pass dtype to ensure that the Series constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3016\u001b[0m         \u001b[1;31m#  does inference in the case where `result` has object-dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3017\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3018\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3019\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    449\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 \u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode.data_manager\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[0;32m    599\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m     \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sanitize_ndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_2d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m             \u001b[1;31m# i.e. PandasDtype(\"O\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "train_Y_preds = nn_model.predict(train_X_scaled)\n",
    "cv_Y_preds = nn_model.predict(cv_X_scaled)\n",
    "\n",
    "print(f'\\ncv MSE: {asymm_mse(cv_Y, cv_Y_preds)}\\n')\n",
    "\n",
    "dfcv = pd.DataFrame(data={'cvPreds': np.reshape(cv_Y_preds, (cv_Y_preds.size,)), 'cvVals': cv_Y})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc30cf-23ea-4a42-b604-670740d3aea6",
   "metadata": {},
   "source": [
    "Note that this cv MSE is ~100 points higher than that produced by the XGBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac69f6d2-1fe3-41c5-9dc0-91bedd506c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "nlargest = dfcv.nlargest(n, ['cvPreds'])\n",
    "nsmallest = dfcv.nsmallest(n, ['cvPreds'])\n",
    "print(f'The {n} largest predictions and their values: \\n{nlargest}\\n')\n",
    "print(f'The {n} smallest predictions and their values: \\n{nsmallest}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551abf5-cfe2-4d87-b879-a7398d3ef8ff",
   "metadata": {},
   "source": [
    "### Here, we've reached a bit of a standstill in the modeling process.\n",
    "Recall from above that these predictions are generated with UNDERESTIMATE_BIAS=1 -- there is no bias towards underestimates in our objective function! Yet all but 3 cross-validation estimates are well under 2%, and all but 3 estimates are in the interval \\[-3, 2\\]%.\n",
    "\n",
    "This is puzzling, and I need to think more about why this would be. These predictions are kind of useless -- using them to create an investment strategy probably wouldn't result in us losing money, but we also likely wouldn't gain much, especially relative to the S&P500 gaining 8% in this time period!\n",
    "\n",
    "However, the XGBoost model seems to be working better, so let's implement a strategy with that model in strategy_simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31d5c3-fee1-45cf-85a8-08de4fc61396",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
