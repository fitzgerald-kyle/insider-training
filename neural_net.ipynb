{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85b09665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nbimporter\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from operator import itemgetter\n",
    "\n",
    "mods = ['exploratory_analysis', 'prep_and_split_data']\n",
    "[sys.modules.pop(mod) for mod in mods if mod in sys.modules]\n",
    "\n",
    "from exploratory_analysis import save_obj, load_obj, returnDataOnDate\n",
    "from prep_and_split_data import prepareForModel, returnXandY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525a07b1-e849-4aaf-a3b8-7afa0cb2b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_cv = pd.read_csv('data/training_and_cv_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c02db72-86a7-46e6-aa28-4865e3759d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_cv = prepareForModel(train_and_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527a5a70-db92-4318-9593-d9d55bbcd66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_XY, train_X, train_Y = returnXandY(train_and_cv, '2021-06-02', '2021-06-26')\n",
    "cv_XY, cv_X, cv_Y = returnXandY(train_and_cv, '2021-06-27', '2021-06-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f335100-3104-4d2a-91f2-dc4f270210e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (4709, 16)\n",
      "cv shape: (524, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape: {train_X.shape}')\n",
    "print(f'cv shape: {cv_X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a97e50",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b828936-c6db-4a88-a517-f80936deae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X)\n",
    "cv_X_scaled = scaler.fit_transform(cv_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb894f1-e2e4-4c53-bb32-48fe30f1e5f7",
   "metadata": {},
   "source": [
    "Here is a StackExchange answer that provides a starting point for deciding on the number of hidden units to include: https://stats.stackexchange.com/a/136542\n",
    "\n",
    "Below is a computation to obtain the absolute maximum number of hidden units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13153c21-12df-4657-ace4-ca672f1f67e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An upper bound for number of hidden units: 138\n"
     ]
    }
   ],
   "source": [
    "Ns = train_X_scaled.shape[0]  # training examples\n",
    "No = 1                           # output neurons\n",
    "Ni = train_X_scaled.shape[1]  # input neurons\n",
    "alpha = 2                        # scale factor\n",
    "\n",
    "Nh = Ns / (alpha*(Ni + No))      # maximum hidden neurons\n",
    "\n",
    "print(f'An upper bound for number of hidden units: {int(Nh)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2a62b-e0b8-4899-bcce-7d0465084faa",
   "metadata": {},
   "source": [
    "This seems like *quite* a lot; we certainly don't need this many hidden units! \n",
    "\n",
    "However, we can remove some of the guesswork by using Keras Tuner. With this tool, we can search the parameter space and also determine an optimal number of hidden units!\n",
    "\n",
    "We have 16 inputs, so let's opt for two hidden layers, one Dense and one Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31ebcc42-8066-4646-9330-0fac84929292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops, numpy_ops\n",
    "numpy_ops.np_config.enable_numpy_behavior()\n",
    "\n",
    "def asymmetric_loss(wgt):\n",
    "    '''This is our custom objective loss function that favors either underestimates (wgt > 1)\n",
    "    or overestimates (0 < wgt < 1).'''\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        diff = wgt/2*math_ops.squared_difference(y_pred, y_true)*(y_true < y_pred).astype(float) + \\\n",
    "                1/2*math_ops.squared_difference(y_pred, y_true)*(y_true >= y_pred).astype(float)\n",
    "        \n",
    "        loss = tf.reduce_mean(diff, axis=-1)\n",
    "\n",
    "        return loss\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71a21264-d7c1-4c04-85ae-0226c2e9bf22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "#UNDERESTIMATE_BIAS = 2.\n",
    "tf.random.set_seed(40)\n",
    "\n",
    "def model_builder(numFeatures):\n",
    "    def builder(tuner):\n",
    "        numUnits = tuner.Int('units', min_value=4, max_value=32, step=4)\n",
    "        learningRate = tuner.Choice('learningRate', values=[1e-2, 1e-3, 1e-4])\n",
    "        UNDERESTIMATE_BIAS = tuner.Choice('UNDERESTIMATE_BIAS', values=[1, 2, 5, 10, 50])\n",
    "        \n",
    "        model = Sequential(\n",
    "            [               \n",
    "                Input(shape=(numFeatures,)),#train_X_scaled.shape[1]\n",
    "                Dense(units=numUnits, activation='relu', name='dense_1'),\n",
    "                Dropout(0.2),\n",
    "                Dense(units=1, activation='linear', name='dense_2')\n",
    "            ], name = 'nn_model' \n",
    "        )\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=learningRate),\n",
    "            loss=asymmetric_loss(UNDERESTIMATE_BIAS),\n",
    "            metrics=[tf.keras.metrics.MeanSquaredError()]\n",
    "        )\n",
    "\n",
    "        return model\n",
    "    return builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2ef163f2-77db-44c0-9e33-f67a3813e696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 90 Complete [00h 00m 08s]\n",
      "mean_squared_error: 664.5034790039062\n",
      "\n",
      "Best mean_squared_error So Far: 553.7682495117188\n",
      "Total elapsed time: 00h 03m 30s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    model_builder(train_X_scaled.shape[1]),\n",
    "    objective='mean_squared_error',\n",
    "    max_epochs=30,\n",
    "    overwrite=True,\n",
    "    directory='tuner logs',\n",
    "    project_name='asymmetric_MSE'\n",
    ")\n",
    "\n",
    "stopEarly = tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "\n",
    "tuner.search(\n",
    "    train_X_scaled, train_Y, \n",
    "    epochs=30,\n",
    "    validation_data=(cv_X_scaled, cv_Y),\n",
    "    callbacks=[stopEarly]\n",
    ")\n",
    "\n",
    "best_hparams = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9b8459e7-cb83-4c07-8dea-da9fddf38565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the best hyperparameter values: \n",
      " {'units': 32, 'learningRate': 0.01, 'UNDERESTIMATE_BIAS': 1, 'tuner/epochs': 10, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "print(f'These are the best hyperparameter values: \\n {best_hparams.values}')\n",
    "nn_model = tuner.hypermodel.build(best_hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "72fb598e-5c57-4a60-9c73-7500f4861c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 822us/step\n",
      "17/17 [==============================] - 0s 742us/step\n",
      "\n",
      "cv MSE: 784.2179197510907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_Y_preds = nn_model.predict(train_X_scaled)\n",
    "cv_Y_preds = nn_model.predict(cv_X_scaled)\n",
    "\n",
    "print(f'\\ncv MSE: {mean_squared_error(cv_Y, cv_Y_preds)}\\n')\n",
    "\n",
    "dfcv = pd.DataFrame(data={'cvPreds': np.reshape(cv_Y_preds, (cv_Y_preds.size,)), 'cvVals': cv_Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ac69f6d2-1fe3-41c5-9dc0-91bedd506c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 largest predictions and their values: \n",
      "        cvPreds      cvVals\n",
      "5153  10.747974   10.305895\n",
      "5156  10.728843   10.305895\n",
      "5157  10.154403   10.305895\n",
      "5245   1.661836  225.657188\n",
      "5246   1.661831  225.657188\n",
      "\n",
      "The 5 smallest predictions and their values: \n",
      "       cvPreds     cvVals\n",
      "5320 -2.920911   6.650825\n",
      "5101 -2.514010  63.048783\n",
      "5283 -2.264927  -2.651003\n",
      "5177 -2.098195  15.254239\n",
      "5435 -2.057703  28.778254\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "nlargest = dfcv.nlargest(n, ['cvPreds'])\n",
    "nsmallest = dfcv.nsmallest(n, ['cvPreds'])\n",
    "print(f'The {n} largest predictions and their values: \\n{nlargest}\\n')\n",
    "print(f'The {n} smallest predictions and their values: \\n{nsmallest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11bb901-a2e9-4b02-9484-af4cc63b5b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
