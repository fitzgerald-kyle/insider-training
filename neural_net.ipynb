{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85b09665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nbimporter\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu\n",
    "from operator import itemgetter\n",
    "\n",
    "mods = ['exploratory_analysis', 'prep_and_split_data']\n",
    "[sys.modules.pop(mod) for mod in mods if mod in sys.modules]\n",
    "\n",
    "from exploratory_analysis import save_obj, load_obj, returnDataOnDate\n",
    "from prep_and_split_data import prepareForModel, returnXandY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "525a07b1-e849-4aaf-a3b8-7afa0cb2b071",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_cv = pd.read_csv('data/training_and_cv_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c02db72-86a7-46e6-aa28-4865e3759d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_cv = prepareForModel(train_and_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "527a5a70-db92-4318-9593-d9d55bbcd66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_XY, train_X, train_Y = returnXandY(train_and_cv, '2021-06-02', '2021-06-26')\n",
    "cv_XY, cv_X, cv_Y = returnXandY(train_and_cv, '2021-06-27', '2021-06-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f335100-3104-4d2a-91f2-dc4f270210e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (4709, 16)\n",
      "cv shape: (524, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f'train shape: {train_X.shape}')\n",
    "print(f'cv shape: {cv_X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a97e50",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b828936-c6db-4a88-a517-f80936deae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_X_scaled = scaler.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb894f1-e2e4-4c53-bb32-48fe30f1e5f7",
   "metadata": {},
   "source": [
    "Here is a StackExchange answer that provides a starting point for deciding on the number of hidden units to include: https://stats.stackexchange.com/a/136542\n",
    "\n",
    "Below is a computation to obtain the absolute maximum number of hidden units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13153c21-12df-4657-ace4-ca672f1f67e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An upper bound for number of hidden units: 138\n"
     ]
    }
   ],
   "source": [
    "Ns = train_X_scaled.shape[0]  # training examples\n",
    "No = 1                           # output neurons\n",
    "Ni = train_X_scaled.shape[1]  # input neurons\n",
    "alpha = 2                        # scale factor\n",
    "\n",
    "Nh = Ns / (alpha*(Ni + No))      # maximum hidden neurons\n",
    "\n",
    "print(f'An upper bound for number of hidden units: {int(Nh)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2a62b-e0b8-4899-bcce-7d0465084faa",
   "metadata": {},
   "source": [
    "This seems like *quite* a lot.\n",
    "\n",
    "Another rule of thumb I've found is that each hidden layer should have ~$\\sqrt{Ni\\cdot No}$ neurons, which results in 4 neurons per layer.\n",
    "\n",
    "Let's start with this and a single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25fe3cf3-9524-4fec-b0df-b56471e1b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(40)\n",
    "nn_model = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(train_X_scaled.shape[1],)),\n",
    "        Dense(units=4, activation='relu', name='layer1'),\n",
    "        #Dense(units=2, activation='relu', name='layer2'),\n",
    "        Dense(units=1, activation='linear', name='layer3')\n",
    "    ], name = \"nn_model\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22b6d4c9-e4c2-42b3-a0ce-edda084b8656",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "148/148 [==============================] - 1s 1ms/step - loss: 159.0682\n",
      "Epoch 2/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 159.0298\n",
      "Epoch 3/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 159.0325\n",
      "Epoch 4/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 159.0139\n",
      "Epoch 5/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.9985\n",
      "Epoch 6/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.9702\n",
      "Epoch 7/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.9958\n",
      "Epoch 8/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.9515\n",
      "Epoch 9/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.9697\n",
      "Epoch 10/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.9685\n",
      "Epoch 11/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.9569\n",
      "Epoch 12/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.9249\n",
      "Epoch 13/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.9294\n",
      "Epoch 14/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.9023\n",
      "Epoch 15/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8835\n",
      "Epoch 16/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.8967\n",
      "Epoch 17/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8735\n",
      "Epoch 18/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8936\n",
      "Epoch 19/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8671\n",
      "Epoch 20/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8786\n",
      "Epoch 21/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.8732\n",
      "Epoch 22/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8447\n",
      "Epoch 23/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8486\n",
      "Epoch 24/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8241\n",
      "Epoch 25/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8335\n",
      "Epoch 26/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.8437\n",
      "Epoch 27/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8335\n",
      "Epoch 28/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8065\n",
      "Epoch 29/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.8007\n",
      "Epoch 30/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7990\n",
      "Epoch 31/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7791\n",
      "Epoch 32/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7689\n",
      "Epoch 33/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7998\n",
      "Epoch 34/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7799\n",
      "Epoch 35/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.7549\n",
      "Epoch 36/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.7779\n",
      "Epoch 37/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7582\n",
      "Epoch 38/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7578\n",
      "Epoch 39/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7437\n",
      "Epoch 40/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7287\n",
      "Epoch 41/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7556\n",
      "Epoch 42/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7128\n",
      "Epoch 43/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7098\n",
      "Epoch 44/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.7195\n",
      "Epoch 45/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6860\n",
      "Epoch 46/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.6962\n",
      "Epoch 47/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6919\n",
      "Epoch 48/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.6840\n",
      "Epoch 49/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6642\n",
      "Epoch 50/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6596\n",
      "Epoch 51/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6929\n",
      "Epoch 52/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6823\n",
      "Epoch 53/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.6606\n",
      "Epoch 54/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6529\n",
      "Epoch 55/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6533\n",
      "Epoch 56/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6628\n",
      "Epoch 57/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6266\n",
      "Epoch 58/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6209\n",
      "Epoch 59/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6197\n",
      "Epoch 60/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6485\n",
      "Epoch 61/100\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 158.6138\n",
      "Epoch 62/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6169\n",
      "Epoch 63/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6028\n",
      "Epoch 64/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6157\n",
      "Epoch 65/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6031\n",
      "Epoch 66/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6017\n",
      "Epoch 67/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6047\n",
      "Epoch 68/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5910\n",
      "Epoch 69/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.6133\n",
      "Epoch 70/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5874\n",
      "Epoch 71/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5715\n",
      "Epoch 72/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5828\n",
      "Epoch 73/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5661\n",
      "Epoch 74/100\n",
      "148/148 [==============================] - 0s 895us/step - loss: 158.5640\n",
      "Epoch 75/100\n",
      "148/148 [==============================] - 0s 897us/step - loss: 158.5827\n",
      "Epoch 76/100\n",
      "148/148 [==============================] - 0s 998us/step - loss: 158.5618\n",
      "Epoch 77/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5872\n",
      "Epoch 78/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5558\n",
      "Epoch 79/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5677\n",
      "Epoch 80/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5784\n",
      "Epoch 81/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5359\n",
      "Epoch 82/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5522\n",
      "Epoch 83/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5589\n",
      "Epoch 84/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5424\n",
      "Epoch 85/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5457\n",
      "Epoch 86/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5536\n",
      "Epoch 87/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5398\n",
      "Epoch 88/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5334\n",
      "Epoch 89/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5472\n",
      "Epoch 90/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5469\n",
      "Epoch 91/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5302\n",
      "Epoch 92/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5130\n",
      "Epoch 93/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5041\n",
      "Epoch 94/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.5049\n",
      "Epoch 95/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.4899\n",
      "Epoch 96/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.4744\n",
      "Epoch 97/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.4547\n",
      "Epoch 98/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.4659\n",
      "Epoch 99/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.4649\n",
      "Epoch 100/100\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 158.4766\n"
     ]
    }
   ],
   "source": [
    "nn_model.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    ")\n",
    "\n",
    "nn_model_fit = nn_model.fit(\n",
    "    train_X_scaled, train_Y,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c5261c8-261d-4955-8486-6e753a312da1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 2ms/step\n",
      "17/17 [==============================] - 0s 2ms/step\n",
      "     TrainPreds  TrainVals\n",
      "229    7.040806  -0.499239\n",
      "230    9.257483   3.456387\n",
      "231    7.835962   8.400529\n",
      "232    6.803262   0.946665\n",
      "233    8.651533  -0.475129\n",
      "234   12.507952  12.418294\n",
      "235    8.197610  17.796711\n",
      "236    8.760069   0.411522\n",
      "237    9.316175   0.665847\n",
      "238    6.555308   1.136853\n",
      "239    6.845170   0.946665\n",
      "240   12.592384  -1.010101\n",
      "241    6.010951   0.744565\n",
      "242    6.425060   0.035832\n",
      "243    6.503365   0.783289\n",
      "\n",
      "      TestPreds   TestVals\n",
      "4938  11.942869  -2.854838\n",
      "4939   9.343163  -1.503758\n",
      "4940  11.697374  -2.854838\n",
      "4941   7.181939  -1.304511\n",
      "4942  11.943060  -2.854838\n",
      "4943   9.810583  57.142857\n",
      "4944  13.463144   5.569006\n",
      "4945  12.083153   3.240172\n",
      "4946   6.387346  -0.502828\n",
      "4947  12.261545  -0.645893\n",
      "4948   6.589577  15.042064\n",
      "4949  12.175924   9.557329\n",
      "4950  12.176893   9.557329\n",
      "4951   8.686260   3.240172\n",
      "4952   7.135557  57.142857\n"
     ]
    }
   ],
   "source": [
    "train_Y_preds = nn_model.predict(train_X_scaled)\n",
    "cv_X_scaled = scaler.fit_transform(cv_X)\n",
    "cv_Y_preds = nn_model.predict(cv_X_scaled)\n",
    "\n",
    "d2 = {'TrainPreds': np.reshape(train_Y_preds, (train_Y_preds.size)), 'TrainVals': train_Y}\n",
    "dfTrain = pd.DataFrame(data=d2)\n",
    "print(dfTrain.head(15))\n",
    "print()\n",
    "d1 = {'cvPreds': np.reshape(cv_Y_preds, (cv_Y_preds.size)), 'cvVals': cv_Y}\n",
    "dfcv = pd.DataFrame(data=d1)\n",
    "print(dfcv.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41f02bdf-1364-4cfa-bc9e-1de78ca9cd8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33955058  0.5153292   0.25442672 -0.49963948]\n",
      " [ 0.8090537  -0.04677701 -0.8416188  -0.43038285]\n",
      " [-0.10451187  0.25276995 -0.9639532   0.3444593 ]\n",
      " [-1.4364793   0.43277752 -1.6644655   0.6104626 ]\n",
      " [-0.08666021  0.2980548   0.57271516  0.58109915]\n",
      " [-0.29034543  0.90744245  1.0659096  -0.31378835]\n",
      " [-0.1928127   0.08368501 -1.3508987   0.15999238]\n",
      " [ 0.5388136   0.42414576 -3.051762   -0.8180944 ]\n",
      " [-0.08579298  1.2191445   2.056615   -1.0101562 ]\n",
      " [ 0.8512917  -0.2672444  -0.08676212 -0.9677913 ]\n",
      " [-1.28855    -0.23726587  0.8006748   0.36757672]\n",
      " [ 0.7694906   0.09131569 -0.7260561   0.7202867 ]\n",
      " [ 0.0503447  -1.3305098  -1.0657406   0.3260037 ]\n",
      " [-0.19754073  0.2613251   0.3447797  -1.0783085 ]\n",
      " [ 0.7727951  -0.05427537 -0.61826134 -0.3786807 ]]\n"
     ]
    }
   ],
   "source": [
    "[layer1, layer2] = nn_model.layers\n",
    "W1,b1 = layer1.get_weights()\n",
    "print(W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31ebcc42-8066-4646-9330-0fac84929292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops import math_ops, numpy_ops\n",
    "numpy_ops.np_config.enable_numpy_behavior()\n",
    "\n",
    "def asymmetric_loss(wgt):\n",
    "    def custom_loss(y_true, y_pred):\n",
    "        diff = wgt/2*math_ops.squared_difference(y_pred, y_true)*(y_true < y_pred).astype(float) + \\\n",
    "                1/2*math_ops.squared_difference(y_pred, y_true)*(y_true >= y_pred).astype(float)\n",
    "        \n",
    "        loss = tf.reduce_mean(diff, axis=-1)\n",
    "\n",
    "        return loss\n",
    "    return custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71a21264-d7c1-4c04-85ae-0226c2e9bf22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "148/148 [==============================] - 1s 2ms/step - loss: 111.9242\n",
      "Epoch 2/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 109.8485\n",
      "Epoch 3/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 109.3248\n",
      "Epoch 4/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 108.7265\n",
      "Epoch 5/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 108.4271\n",
      "Epoch 6/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 108.1274\n",
      "Epoch 7/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 107.8281\n",
      "Epoch 8/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 107.5461\n",
      "Epoch 9/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 107.5751\n",
      "Epoch 10/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 107.4102\n",
      "Epoch 11/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 107.1128\n",
      "Epoch 12/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 107.1392\n",
      "Epoch 13/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.8847\n",
      "Epoch 14/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.8394\n",
      "Epoch 15/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.7549\n",
      "Epoch 16/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.6998\n",
      "Epoch 17/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.6284\n",
      "Epoch 18/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.4956\n",
      "Epoch 19/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.5421\n",
      "Epoch 20/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.3856\n",
      "Epoch 21/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.1506\n",
      "Epoch 22/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.2892\n",
      "Epoch 23/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.2186\n",
      "Epoch 24/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.3563\n",
      "Epoch 25/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.1541\n",
      "Epoch 26/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.3396\n",
      "Epoch 27/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.1409\n",
      "Epoch 28/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.9908\n",
      "Epoch 29/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 106.0612\n",
      "Epoch 30/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.7798\n",
      "Epoch 31/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.8085\n",
      "Epoch 32/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.7779\n",
      "Epoch 33/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.7708\n",
      "Epoch 34/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.6545\n",
      "Epoch 35/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.6146\n",
      "Epoch 36/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.6205\n",
      "Epoch 37/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.4526\n",
      "Epoch 38/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.4710\n",
      "Epoch 39/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.5587\n",
      "Epoch 40/40\n",
      "148/148 [==============================] - 0s 2ms/step - loss: 105.3457\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(40)\n",
    "nn_model_custom = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(train_X_scaled.shape[1],)),\n",
    "        Dense(units=4, activation='relu', name='layer1'),\n",
    "        #Dense(units=2, activation='relu', name='layer2'),\n",
    "        Dense(units=1, activation='linear', name='layer3')\n",
    "    ], name = \"nn_model_custom\" \n",
    ")\n",
    "\n",
    "#weights = nn_model_custom.get_weights()\n",
    "#reset_model = lambda model: model.set_weights(weights)\n",
    "\n",
    "nn_model_custom.compile(\n",
    "    loss=asymmetric_loss(10.),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    ")\n",
    "\n",
    "nn_model_fit_custom = nn_model_custom.fit(\n",
    "    train_X_scaled, train_Y,\n",
    "    epochs=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72fb598e-5c57-4a60-9c73-7500f4861c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 0s 2ms/step\n",
      "17/17 [==============================] - 0s 3ms/step\n",
      "     TrainPreds  TrainVals\n",
      "229    1.646459  -0.499239\n",
      "230    2.330482   3.456387\n",
      "231    3.286908   8.400529\n",
      "232    0.876429   0.946665\n",
      "233    1.923940  -0.475129\n",
      "234    2.633893  12.418294\n",
      "235    3.772491  17.796711\n",
      "236    1.885907   0.411522\n",
      "237    2.469335   0.665847\n",
      "238    1.028203   1.136853\n",
      "239    0.860074   0.946665\n",
      "240    3.585289  -1.010101\n",
      "241    0.999431   0.744565\n",
      "242    1.269123   0.035832\n",
      "243    1.097346   0.783289\n",
      "\n",
      "      TestPreds   TestVals\n",
      "4938   3.782362  -2.854838\n",
      "4939   3.193410  -1.503758\n",
      "4940   5.931743  -2.854838\n",
      "4941   1.544710  -1.304511\n",
      "4942   3.782386  -2.854838\n",
      "4943   3.282927  57.142857\n",
      "4944   6.605915   5.569006\n",
      "4945   3.757955   3.240172\n",
      "4946   1.073820  -0.502828\n",
      "4947   3.112996  -0.645893\n",
      "4948   5.879294  15.042064\n",
      "4949   3.519294   9.557329\n",
      "4950   3.524330   9.557329\n",
      "4951   1.513879   3.240172\n",
      "4952   2.501349  57.142857\n"
     ]
    }
   ],
   "source": [
    "train_Y_preds = nn_model_custom.predict(train_X_scaled)\n",
    "cv_X_scaled = scaler.fit_transform(cv_X)\n",
    "cv_Y_preds = nn_model_custom.predict(cv_X_scaled)\n",
    "\n",
    "d2 = {'TrainPreds': np.reshape(train_Y_preds, (train_Y_preds.size)), 'TrainVals': train_Y}\n",
    "dfTrain = pd.DataFrame(data=d2)\n",
    "print(dfTrain.head(15))\n",
    "print()\n",
    "d1 = {'cvPreds': np.reshape(cv_Y_preds, (cv_Y_preds.size)), 'cvVals': cv_Y}\n",
    "dfcv = pd.DataFrame(data=d1)\n",
    "print(dfcv.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecd1a52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
